{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1dc097b-bdfe-4ad0-9619-39512aa8519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2075fecd-fbed-45c1-b762-fb1806c5f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import nbimporter\n",
    "from utils.vault_scripts import read_root_token, get_secret_from_vault\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, when, lit, expr\n",
    "from pyspark.sql.types import LongType\n",
    "import datetime\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e15a758-9886-49e2-9b56-c4c5cbffc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ExpDataAnalysisExchangeRates\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff64d2d-4c8d-4cec-9d50-4201347f4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf = spark._jsc.hadoopConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16463b91-01b2-41c9-9bfe-c8e0dff585ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_KEY_ID = get_secret_from_vault(\"aws1\", \"keyid\")\n",
    "AWS_ACCESS_KEY = get_secret_from_vault(\"aws2\", \"accesskey\")\n",
    "AWS_S3_BUCKET = get_secret_from_vault(\"aws3\", \"s3bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f512f5-986d-4c0a-a36e-d3e579f8d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf.set(\"fs.s3a.access.key\", AWS_KEY_ID)\n",
    "hadoopConf.set(\"fs.s3a.secret.key\", AWS_ACCESS_KEY)\n",
    "hadoopConf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "523763a0-e2bb-46cf-8056-98885d04ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_exchange_data(bucket, layer, path, symbol):\n",
    "    exchange_rate_data_path = f\"s3a://{bucket}/{layer}/{path}/{symbol}/*.json\"\n",
    "    df = spark.read.json(exchange_rate_data_path)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a20f0a-01e0-4f0b-9427-6b996b80beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_exchange_data(df):\n",
    "    df_exploded = df.select(\n",
    "        F.explode(\"Data.Data\").alias(\"data\"),\n",
    "        \"Data.TimeFrom\",\n",
    "        \"Data.TimeTo\"\n",
    "    )\n",
    "    \n",
    "    df_exploded = df_exploded.select(\n",
    "        F.col(\"data.open\").alias(\"open_price\"),\n",
    "        F.col(\"data.close\").alias(\"close_price\"), \n",
    "        F.col(\"data.high\").alias(\"high_price\"),\n",
    "        F.col(\"data.low\").alias(\"low_price\"),\n",
    "        F.col(\"data.conversionSymbol\").alias(\"conversion_symbol\"),\n",
    "        F.col(\"data.conversionType\").alias(\"conversion_type\"), \n",
    "        F.col(\"data.time\").alias(\"time\"),\n",
    "        F.col(\"data.volumefrom\").alias(\"volume_from\"),\n",
    "        F.col(\"data.volumeto\").alias(\"volume_to\"),\n",
    "        F.col(\"TimeFrom\").alias(\"data_time_from\"),\n",
    "        F.col(\"TimeTo\").alias(\"data_time_to\"),\n",
    "    )\n",
    "    \n",
    "    return df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50cf94e4-996e-4ed1-8cd9-e79aad899c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_exchange_data_df(transformed_df):\n",
    "\n",
    "    start_date = datetime.datetime(2024, 7, 1)\n",
    "    end_date = datetime.datetime(2024, 10, 1)\n",
    "\n",
    "    # Convert to milliseconds\n",
    "    start_timestamp = int(start_date.timestamp())\n",
    "    end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "    filtered_df = transformed_df.filter(\n",
    "        (transformed_df.time >= start_timestamp) & \n",
    "        (transformed_df.time <= end_timestamp)\n",
    "    )\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "887dbcb4-de62-49f4-8f82-a8e0ba70e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_exchange_data_to_s3(bucket, layer, path, symbol, data):\n",
    "\n",
    "    exchange_rate_data_path = f\"s3a://{bucket}/{layer}/{path}/{symbol}/\"\n",
    "    data.write.mode(\"overwrite\").json(exchange_rate_data_path)\n",
    "    \n",
    "    print(f\"Data successfully saved to: {exchange_rate_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b060aa5d-db32-429f-9eb7-a826ec69cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYMBOLS = [\"ETH\", \"POL\", \"USDC\", \"WETH\"]\n",
    "SYMBOLS = [\"ETH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d4fbbe9-d769-4fd1-9474-af312eee93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to: s3a://nft-framework-storage-ca3f7714-6047-47c1-940e-72b72f0c97ff/prepared/exchange_rates_hourly/ETH/\n"
     ]
    }
   ],
   "source": [
    "for symbol in SYMBOLS:\n",
    "    df = read_exchange_data(AWS_S3_BUCKET, \"raw\", \"exchange_rates_hourly_usdt\", symbol)\n",
    "    transformed_df = transform_exchange_data(df)\n",
    "    filtered_df = filter_exchange_data_df(transformed_df)\n",
    "    save_exchange_data_to_s3(AWS_S3_BUCKET, \"prepared\", \"exchange_rates_hourly\", symbol, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "452ee525-15d8-4c96-98f1-f86ba2588553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(open_price=3165.07, close_price=3146.45, high_price=3165.76, low_price=3140.41, conversion_symbol='', conversion_type='direct', time=1722574800, volume_from=12500.54, volume_to=39420155.2, data_time_from=1722574800, data_time_to=1729774800)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3ed9853-712d-49f2-8824-661594c84aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|min_event_timestamp|max_event_timestamp|\n",
      "+-------------------+-------------------+\n",
      "|2024-07-01 00:00:00|2024-10-01 00:00:00|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_max_timestamps = filtered_df.agg(\n",
    "    F.from_unixtime(F.min(\"time\")).alias(\"min_event_timestamp\"),\n",
    "    F.from_unixtime(F.max(\"time\")).alias(\"max_event_timestamp\")\n",
    ")\n",
    "min_max_timestamps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f790a445-7b0b-4374-9e9e-38e06cc1fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"s3a://{AWS_S3_BUCKET}/prepared/exchange_rates_hourly/ETH/*.json\"\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f43b1668-058b-4659-8248-203fc59b57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- close_price: double (nullable = true)\n",
      " |-- conversion_symbol: string (nullable = true)\n",
      " |-- conversion_type: string (nullable = true)\n",
      " |-- data_time_from: long (nullable = true)\n",
      " |-- data_time_to: long (nullable = true)\n",
      " |-- high_price: double (nullable = true)\n",
      " |-- low_price: double (nullable = true)\n",
      " |-- open_price: double (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- volume_from: double (nullable = true)\n",
      " |-- volume_to: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27e9afef-99a6-4804-9f47-b8bc62285405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(open_price=3165.07, close_price=3146.45, high_price=3165.76, low_price=3140.41, conversion_symbol='', conversion_type='direct', time=1722574800, volume_from=12500.54, volume_to=39420155.2, data_time_from=1722574800, data_time_to=1729774800)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb074362-8a72-496f-8af9-a6ab05e0e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing records: Expected 2208 records, but found 2210 records.\n"
     ]
    }
   ],
   "source": [
    "# Sample checks - > records by each hour\n",
    "# TODO\n",
    "\n",
    "df = filtered_df\n",
    "\n",
    "start_date = datetime(2024, 7, 1)\n",
    "end_date = datetime(2024, 10, 1)\n",
    "\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "total_hours = (end_timestamp - start_timestamp) // 3600\n",
    "\n",
    "# Check if the DataFrame contains the expected number of records\n",
    "actual_hours = df.filter((df.time >= start_timestamp) & (df.time <= end_timestamp)).count()\n",
    "\n",
    "if actual_hours == total_hours:\n",
    "    print(\"All hourly records are present.\")\n",
    "else:\n",
    "    print(f\"Missing records: Expected {total_hours} records, but found {actual_hours} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61083d49-aa55-4075-a9d1-68794cd76468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records based on `data_time_from` and `data_time_to`\n",
    "df_duplicates = df.groupBy(\"data_time_from\", \"data_time_to\").count().filter(\"count > 1\")\n",
    "\n",
    "duplicate_count = df_duplicates.count()\n",
    "if duplicate_count == 0:\n",
    "    print(\"No duplicate records found.\")\n",
    "else:\n",
    "    print(f\"Found {duplicate_count} duplicate records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c53b1-2bce-4b2b-a263-5cd9acb5eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of critical columns to check for missing values\n",
    "critical_columns = [\"open_price\", \"close_price\", \"high_price\", \"low_price\", \n",
    "                    \"conversion_symbol\", \"conversion_type\", \"volume_from\", \"volume_to\"]\n",
    "\n",
    "# Check for rows with null values in critical columns\n",
    "missing_values_df = df.filter(\n",
    "    F.reduce(\n",
    "        lambda a, b: a | b,\n",
    "        [F.col(col).isNull() | (F.col(col) == '') for col in critical_columns]\n",
    "    )\n",
    ")\n",
    "\n",
    "missing_values_count = missing_values_df.count()\n",
    "if missing_values_count == 0:\n",
    "    print(\"No missing values in critical columns.\")\n",
    "else:\n",
    "    print(f\"Found {missing_values_count} rows with missing values in critical columns.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
