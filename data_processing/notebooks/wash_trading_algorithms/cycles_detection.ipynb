{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100932ae-2718-41e2-972b-d71cfc8a2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some transformation notebooks and read data from this location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6639dbcd-4905-41b3-9d0f-57b791105bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cd6d6e-77ec-40ff-b68e-68a55583edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work') # here add notebooks if fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768a925a-4b96-4816-9ef2-25c194129149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import nbimporter\n",
    "from utils.vault_scripts import read_root_token, get_secret_from_vault\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col, when, lit, expr\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.sql.functions import col, to_timestamp, lag, unix_timestamp, expr\n",
    "from pyspark.sql.window import Window\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90daded-38a0-4e08-8ac2-9defebbfdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DetectCyclesApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf8abf8-deff-42a6-acc5-2855c840b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf = spark._jsc.hadoopConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7cdb3a-2a8f-474e-9883-865ac614e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_KEY_ID = get_secret_from_vault(\"aws1\", \"keyid\")\n",
    "AWS_ACCESS_KEY = get_secret_from_vault(\"aws2\", \"accesskey\")\n",
    "AWS_S3_BUCKET = get_secret_from_vault(\"aws3\", \"s3bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69dc363c-cf30-4ab3-8f02-dd56af119f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf.set(\"fs.s3a.access.key\", AWS_KEY_ID)\n",
    "hadoopConf.set(\"fs.s3a.secret.key\", AWS_ACCESS_KEY)\n",
    "hadoopConf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c04603a5-8e6b-4ed0-a4a3-f6f66675f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3a://{AWS_S3_BUCKET}/raw/opensea_data/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b00e45d-0890-46be-af45-68fccfb7fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936342e3-a8a8-4ce5-81ca-128d277dbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asset_events = df.select(explode(col(\"asset_events\")).alias(\"event\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66a62fe4-6347-41ee-b9fe-039681e5c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asset_events_flat = df_asset_events.select(\n",
    "    col(\"event.transaction\"),\n",
    "    col(\"event.event_type\"),\n",
    "    col(\"event.buyer\"),\n",
    "    col(\"event.seller\"),\n",
    "    col(\"event.from_address\"),\n",
    "    col(\"event.to_address\"),\n",
    "    col(\"event.quantity\"),\n",
    "    col(\"event.event_timestamp\"),\n",
    "    col(\"event.order_hash\"),\n",
    "    col(\"event.nft.identifier\"),\n",
    "    col(\"event.nft.collection\"),\n",
    "    col(\"event.nft.contract\"),\n",
    "    col(\"event.payment.decimals\"),\n",
    "    col(\"event.payment.quantity\").alias(\"payment_quantity\"),\n",
    "    col(\"event.payment.symbol\"),\n",
    "    col(\"event.payment.token_address\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9babfa5-d1fd-4160-9e60-e671b98b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp to a proper timestamp format\n",
    "df_asset_events_flat = df_asset_events_flat.withColumn(\"event_timestamp\", to_timestamp(\"event_timestamp\"))\n",
    "\n",
    "# Create a window partitioned by token identifier and ordered by time\n",
    "windowSpec = Window.partitionBy(\"identifier\").orderBy(\"event_timestamp\")\n",
    "\n",
    "# Add previous buyer and seller addresses for each transaction within the token's sales history\n",
    "df_asset_events_flat = df_asset_events_flat.withColumn(\"prev_buyer\", lag(\"to_address\").over(windowSpec)) \\\n",
    "                                           .withColumn(\"prev_seller\", lag(\"from_address\").over(windowSpec)) \\\n",
    "                                           .withColumn(\"prev_event_timestamp\", lag(\"event_timestamp\").over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defa1771-d80a-45cb-b3a8-5ac7f3246133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(transaction='0xb2e890c6fc844a7eaa1067d00299263f7aaf0d1d9d416c0891b5986d64c9208e', event_type='transfer', buyer=None, seller=None, from_address='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', to_address='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', quantity=1, event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59), order_hash=None, identifier='100', collection='boredapeyachtclub', contract='0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d', decimals=None, payment_quantity=None, symbol=None, token_address=None, prev_buyer=None, prev_seller=None, prev_event_timestamp=None),\n",
       " Row(transaction='0xb2e890c6fc844a7eaa1067d00299263f7aaf0d1d9d416c0891b5986d64c9208e', event_type='sale', buyer='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', seller='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', from_address=None, to_address=None, quantity=1, event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59), order_hash='0xee59198a69ffee09f699b6788c4c9217a8bec046ab3e352df236c3f9713de87e', identifier='100', collection='boredapeyachtclub', contract='0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d', decimals=18, payment_quantity='27000000000000000000', symbol='ETH', token_address='0x0000000000000000000000000000000000000000', prev_buyer='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', prev_seller='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', prev_event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59)),\n",
       " Row(transaction='0xb2e890c6fc844a7eaa1067d00299263f7aaf0d1d9d416c0891b5986d64c9208e', event_type='transfer', buyer=None, seller=None, from_address='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', to_address='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', quantity=1, event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59), order_hash=None, identifier='100', collection='boredapeyachtclub', contract='0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d', decimals=None, payment_quantity=None, symbol=None, token_address=None, prev_buyer=None, prev_seller=None, prev_event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59)),\n",
       " Row(transaction='0xb2e890c6fc844a7eaa1067d00299263f7aaf0d1d9d416c0891b5986d64c9208e', event_type='sale', buyer='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', seller='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', from_address=None, to_address=None, quantity=1, event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59), order_hash='0xee59198a69ffee09f699b6788c4c9217a8bec046ab3e352df236c3f9713de87e', identifier='100', collection='boredapeyachtclub', contract='0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d', decimals=18, payment_quantity='27000000000000000000', symbol='ETH', token_address='0x0000000000000000000000000000000000000000', prev_buyer='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', prev_seller='0x6e353e91cb721fda5b3131ac40d945f7775c95e7', prev_event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59)),\n",
       " Row(transaction='0x57a3051198a54a0f1fa9ccff97b8b37b7f4afa94d79e576ad9b9139706fdb90d', event_type='transfer', buyer=None, seller=None, from_address='0x96d618adc74b18e26968a2aa8ad1ec3f95940d64', to_address='0x0c0f1283968740bc3dcd56b8544cd6980dd8db65', quantity=1, event_timestamp=datetime.datetime(2023, 9, 2, 4, 24, 11), order_hash=None, identifier='100', collection='boredapeyachtclub', contract='0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d', decimals=None, payment_quantity=None, symbol=None, token_address=None, prev_buyer=None, prev_seller=None, prev_event_timestamp=datetime.datetime(2023, 8, 24, 16, 53, 59))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_asset_events_flat.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5df46b5-f08a-4c85-a43b-7e42e1362c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only transfer events\n",
    "df_asset_transfers = df_asset_events_flat.filter(col(\"event_type\") == \"transfer\")\n",
    "\n",
    "# Create a window partitioned by token identifier and ordered by event timestamp\n",
    "windowSpec = Window.partitionBy(\"identifier\").orderBy(\"event_timestamp\")\n",
    "\n",
    "# Add previous buyer (to_address) and previous event timestamp for each token transfer\n",
    "df_asset_transfers = df_asset_transfers.withColumn(\"prev_buyer\", lag(\"to_address\").over(windowSpec)) \\\n",
    "                                       .withColumn(\"prev_event_timestamp\", lag(\"event_timestamp\").over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ebfe852-1666-46c1-99c4-22440d8f72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time difference in seconds between the current and previous transfer events\n",
    "df_asset_transfers = df_asset_transfers.withColumn(\"time_diff\", unix_timestamp(col(\"event_timestamp\")) - unix_timestamp(col(\"prev_event_timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc23787b-3f41-4b84-93eb-dfff60d0a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter where the previous buyer is the current seller and the time difference is less than 30 days (2592000 seconds)\n",
    "df_wash_transfers = df_asset_transfers.filter((col(\"from_address\") == col(\"prev_buyer\")) & (col(\"time_diff\") <= 2592000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "027bd0a5-cd4c-4bf0-8f20-24a083da3608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  id|\n",
      "+--------------------+\n",
      "|0x532948a2bf980a0...|\n",
      "|0x7d462af7fb6aa7b...|\n",
      "|0xa66515af0dfd9aa...|\n",
      "|0x99d73d76f0058f4...|\n",
      "|0x174603889ff6086...|\n",
      "|0x8d3ea02a80b19c8...|\n",
      "|0x69986d5af481c14...|\n",
      "|0x484a8e9d2d135c5...|\n",
      "|0xafc786f195f4a1c...|\n",
      "|0x65249532663d15a...|\n",
      "|0x7051499622ab354...|\n",
      "|0xf15c93562bc3944...|\n",
      "|0xc67db0df9222389...|\n",
      "|0xb5bc4849b531b29...|\n",
      "|0x17b70f6b0dd3bf1...|\n",
      "|0x021cba2d12aa986...|\n",
      "|0x3e6527de2cfec82...|\n",
      "|0x142668dc89e7e69...|\n",
      "|0x945191ab90d5b51...|\n",
      "|0x096913c0c00a9f9...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+-------------------+\n",
      "|                 src|                 dst|    event_timestamp|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|0xdbfd76af2157dc1...|0xdbfd76af2157dc1...|2023-08-20 08:33:11|\n",
      "|0x2e9a18d66f2fc53...|0xe0b6e70261db8ef...|2023-08-20 08:28:47|\n",
      "|0xc67db0df9222389...|0xea5b1f2f29d89dd...|2023-08-20 08:24:11|\n",
      "|0xa8d87df83755179...|0xdb5485c85bd95f3...|2023-08-20 08:08:47|\n",
      "|0xdbfd76af2157dc1...|0x501036f867924cd...|2023-08-20 07:39:23|\n",
      "|0xcafba4ca4a4886a...|0x29469395eaf6f95...|2023-08-20 07:28:59|\n",
      "|0x61fbb052daf37a3...|0xaaa2da255df9ee7...|2023-08-20 07:28:35|\n",
      "|0x945191ab90d5b51...|0xaaa2da255df9ee7...|2023-08-20 07:28:35|\n",
      "|0x29469395eaf6f95...|0x61fbb052daf37a3...|2023-08-20 07:27:35|\n",
      "|0x6332e40af90c0c6...|0x29469395eaf6f95...|2023-08-20 05:32:11|\n",
      "|0xc58d63d59ad6893...|0x6332e40af90c0c6...|2023-08-20 05:30:47|\n",
      "|0xef2bce91cc8d688...|0x29469395eaf6f95...|2023-08-20 05:18:23|\n",
      "|0x48bc8ca6d9369fa...|0x66666f58de1bcd7...|2023-08-20 04:55:59|\n",
      "|0xf3ebf519c3f3212...|0x29469395eaf6f95...|2023-08-20 04:48:47|\n",
      "|0x29469395eaf6f95...|0x020ca66c30bec2c...|2023-08-20 04:39:11|\n",
      "|0xbc3ac1ec5f155ab...|0x020ca66c30bec2c...|2023-08-20 04:34:35|\n",
      "|0x2ad412ab1e3c791...|0x29469395eaf6f95...|2023-08-20 04:33:11|\n",
      "|0x0097b9cfe64455e...|0x3dae7ad6015efe0...|2023-08-20 04:32:47|\n",
      "|0x011c23b3aadaf3d...|0xdb5485c85bd95f3...|2023-08-20 04:16:35|\n",
      "|0x011c23b3aadaf3d...|0xdb5485c85bd95f3...|2023-08-20 04:16:35|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create wallet nodes (distinct wallet addresses)\n",
    "wallets = df_asset_transfers.select(\"from_address\").union(df_asset_transfers.select(\"to_address\")).distinct().withColumnRenamed(\"from_address\", \"id\")\n",
    "\n",
    "# Create edges (transactions between wallets for transfers)\n",
    "edges_transfers = df_asset_transfers.select(col(\"from_address\").alias(\"src\"), col(\"to_address\").alias(\"dst\"), \"event_timestamp\")\n",
    "\n",
    "# Create the transfer graph \n",
    "graph_transfers = GraphFrame(wallets, edges_transfers)\n",
    "\n",
    "# Display the wallet nodes and transfer edges\n",
    "graph_transfers.vertices.show()\n",
    "graph_transfers.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9bd012a-6c12-4489-ab84-7c45f6390804",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Find all simple cycles in the graph (this may take time depending on the size of the graph)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m cycles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_transfers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Check if we found any cycles\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/networkx/algorithms/cycles.py:235\u001b[0m, in \u001b[0;36msimple_cycles\u001b[0;34m(G, length_bound)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m directed:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _directed_cycle_search(G, length_bound)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/networkx/algorithms/cycles.py:282\u001b[0m, in \u001b[0;36m_directed_cycle_search\u001b[0;34m(G, length_bound)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _johnson_cycle_search(Gc, [v])\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/networkx/algorithms/cycles.py:386\u001b[0m, in \u001b[0;36m_johnson_cycle_search\u001b[0;34m(G, path)\u001b[0m\n\u001b[1;32m    385\u001b[0m closed \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n\u001b[1;32m    387\u001b[0m     nbrs \u001b[38;5;241m=\u001b[39m stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3547\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3545\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   3546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m         result\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;241m=\u001b[39m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshowtraceback(running_compiled_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert edges to Pandas for easy graph manipulation in NetworkX\n",
    "edges_transfers_pd = edges_transfers.select(col(\"src\"), col(\"dst\")).toPandas()\n",
    "\n",
    "# Ensure there are no duplicate edges to avoid unnecessary noise\n",
    "edges_transfers_pd = edges_transfers_pd.drop_duplicates()\n",
    "\n",
    "# Create a directed graph from the transfers data\n",
    "G_transfers = nx.from_pandas_edgelist(edges_transfers_pd, source='src', target='dst', create_using=nx.DiGraph())\n",
    "\n",
    "# Find all simple cycles in the graph (this may take time depending on the size of the graph)\n",
    "cycles = list(nx.simple_cycles(G_transfers))\n",
    "\n",
    "# Check if we found any cycles\n",
    "if cycles:\n",
    "    # Get a random cycle (we are using the first cycle found here for simplicity)\n",
    "    cycle = cycles[0]\n",
    "    \n",
    "    # Generate edges for this cycle\n",
    "    cycle_edges = [(cycle[i], cycle[i+1]) for i in range(len(cycle) - 1)]\n",
    "    cycle_edges.append((cycle[-1], cycle[0]))  # Close the cycle by connecting the last to the first node\n",
    "    \n",
    "    # Create a new subgraph containing only the cycle\n",
    "    G_cycle = nx.DiGraph()\n",
    "    G_cycle.add_edges_from(cycle_edges)\n",
    "    \n",
    "    # Draw the graph with just this cycle\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(G_cycle, with_labels=True, node_size=700, node_color='lightblue', font_size=10, font_weight='bold', edge_color='gray')\n",
    "    plt.title(f\"Cycle: {' -> '.join(cycle)}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No cycles found in the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea42f26-0105-4c22-b8e0-bf1bd0b35c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wash trades: 50.43%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter only transfer events\n",
    "df_asset_transfers = df_asset_events_flat.filter(col(\"event_type\") == \"transfer\")\n",
    "\n",
    "# Step 2: Create a window partitioned by token identifier and ordered by event timestamp\n",
    "windowSpec = Window.partitionBy(\"identifier\").orderBy(\"event_timestamp\")\n",
    "\n",
    "# Step 3: Add previous buyer (to_address) and previous event timestamp for each token transfer\n",
    "df_asset_transfers = df_asset_transfers.withColumn(\"prev_buyer\", lag(\"to_address\").over(windowSpec)) \\\n",
    "                                       .withColumn(\"prev_event_timestamp\", lag(\"event_timestamp\").over(windowSpec))\n",
    "\n",
    "# Step 4: Calculate the time difference in seconds between the current and previous transfer events\n",
    "df_asset_transfers = df_asset_transfers.withColumn(\"time_diff\", unix_timestamp(col(\"event_timestamp\")) - unix_timestamp(col(\"prev_event_timestamp\")))\n",
    "\n",
    "# Step 5: Filter where the previous buyer is the current seller and the time difference is less than 30 days (2592000 seconds)\n",
    "df_wash_transfers = df_asset_transfers.filter((col(\"from_address\") == col(\"prev_buyer\")) & (col(\"time_diff\") <= 2592000))\n",
    "\n",
    "# Step 6: Count total transfer transactions\n",
    "total_transfers = df_asset_transfers.count()\n",
    "\n",
    "# Step 7: Count wash trade (cyclical) transactions\n",
    "wash_trades_count = df_wash_transfers.count()\n",
    "\n",
    "# Step 8: Calculate the percentage of wash trades\n",
    "percentage_wash_trades = (wash_trades_count / total_transfers) * 100\n",
    "\n",
    "# Step 9: Output the result\n",
    "print(f\"Percentage of wash trades: {percentage_wash_trades:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623947f-88af-4e41-bbd8-564794ca3e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
